---
head:
  - - link
    - rel: stylesheet
      href: https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css
---

# 语义消歧

单词或字词往往不只有一种意思，但在特定语境下却往往只有一种意思，这即导致了语义的歧义，而语义消歧（Word Sense Disambiguation）旨在给出某个语境中单词或字词的具体语义。

## 背景及定义

自然语言中，很多单词或字词会有许多可能的含义，语义消歧任务需要根据给定的上下文和带有歧义的单词或自己及其可能含义确定带有歧义的单词的具体含义。一般地，语义消歧任务的输入是带有模糊语义单词或字词的上下为和该单词或字词的可能的含义，输出为该上下文中该模糊单词的语义标签，模型需要从上下文解析出特征并与已有的知识比较。

## 有监督学习、无监督学习和半监督学习

有监督学习，即训练数据包含所有的标注，可以直接使用，因而常常是分类任务。半监督学习，即初始时仅有很少的一部分数据有标注，需要在训练的过程中实现自举，标注其他数据。无监督学习则意味着所有的训练数据都没有标注，因而常常为聚类任务。

## 朴素贝叶斯

有监督的语义消歧可以使用朴素贝叶斯模型，设上下文为 $C$ ， $w$ 表示单词，其语义可能为 $s_k$ ，我们需要求解的是

$$
argmax P(s_k|C)
$$

利用贝叶斯公式，这可以有

$$
P(s_k|C) = \frac{P(s_k)P(C|s_k)}{P(C)}
$$

由于分母是相同的，我们只考虑分子，即 $P(s_k)P(C|s_k)$ ，我们做一个假设，认为单词出现是独立的，从而

$$
P(v_x|s_k) = \frac{Count(v_x, s_k)}{Count(s_k)}
$$

而

$$
P(C|s_k) = \prod\limits_{v_x \in C} P(v_x|s_k)
$$

而

$$
P(s_k) = \frac{Count(s_k)}{Count(w)}
$$

## 语义消歧模型的评估

评估语义消歧模型本质上是评价一个机器学习模型，比较简单的方法是通过准确率度量，具体来说，将预测的语义标签与实际标签相同的样本数除以总的样本数。但考虑一个问题，如果一个单词有 $90\%$ 的可能是某个语义，而其他的语义仅占 $10\%$ ，而模型始终只输出 $90\%$ 的那个语义，那么准确率可以达到 $90\%$ ，但这样的模型在一些问题中不应该被认为是好的模型。为此，我们需要寻找新的度量指标。

考虑一个二分类问题，或者说一个只有两种可能语义标签的语义消歧任务，设置其中一种标签为正标签（Positive），而另一种为负标签（Negative），那么模型的预测结果有下面表格的四种

| | Positive(Gold Standards) | Negative(Gold Standards) |
| :--: | :--: | :--: |
| Positive(Your Output) | true positive | false positive |
| Negative(Your Output) | false negative | true negative |

简记为

| | Positive(Gold Standards) | Negative(Gold Standards) |
| :--: | :--: | :--: |
| Positive(Your Output) | tp | fp |
| Negative(Your Output) | fn | tn |

从而准确率即为

$$
Accuracy = \frac{tp + tn}{tp + fp + fn + tn}
$$

我们可以考虑定义精确度为模型预测某个标签的准确率，以Positive为例，即

$$
Precision = \frac{tp}{tp+fp}
$$

而召回率为真实标签为某个标签的样本中被模型正确标记为该标签的概率，同样以Positive为例，即

$$
Recall = \frac{tp}{tp+fn}
$$

基于此，我们定义**F-measure**为精确度与召回率的加权调和平均

$$
F_{\beta} = \frac{1+\beta^2}{\frac{1}{Pre} + \frac{\beta^2}{Rec}} = \frac{(\beta^2+1)Pre\times Rec}{\beta^2\times Pre + Rec}
$$

基于此再定义Macro F1为各个类型的F1的平均，而Micro F1为整体的F1（即对整体计算精确度和召回率再计算F1）。

## 若干假设

对于语义消歧任务，我们可以作如下几个简化的假设：

1. 最常见的语义（Most Frequent Sense, MFS），即识别出最常见的语义并默认使用这一语义。
2. 每个话语一个语义（One Sense per Discourse），即认为一个话语中出现的一个单词往往只有一个语义。
3. 每种搭配一个语义（One Sense per Collocation），即认为一种搭配中的单词往往只有一个语义。

基于这些假设，比如 MFS ，实现的语义消歧模型的准确率也能达到 $65\%$ 。

## 一些WSD模型和较新的发展

一个简单的模型是 Lesk 模型，将上下文与词典中各个语义的定义等比较，从而找到最相似的作为输出的语义标签。传统方法中最好的模型之一是IMS模型，通过各种特征的组合来判断语义，在传统方法中长期占据最好的模型的位置。进入神经网络时代，通过各种探索，也逐步取得进展，也有稍微超过了IMS模型，而到了预训练时代，基于预训练模型的WSD模型取得了很好的效果，大大超过了IMS模型。

语义消歧往往需要大量的标注数据，而这些标注只有专业的语言学家才能标注，因而发展出了一种新的范式，上下文语义（Word-in-Context, WiC），其任务改为判断两个语句中的两个给定的单词语义是否相同，这个任务的标注基本上只要是以该语言为母语的人都可以进行，对于跨语言的可能需要较高的要求。
