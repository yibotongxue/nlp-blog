---
head:
  - - link
    - rel: stylesheet
      href: https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css
---

# 参数高效微调

预训练的语言模型，如果要应用于下游的任务，往往可以进行微调，即在下游任务的新的数据集上进行训练。微调分为全参数微调和参数高效微调，全参数微调对模型的参数进行微调，而参数高效微调则冻结大部分参数，仅修改部分参数，更为高效。本文主要为大语言模型基础与对齐课程第六讲的笔记，并参考了[博客](https://wjn1996.blog.csdn.net/article/details/120607050)、[知乎文章](https://zhuanlan.zhihu.com/p/621700272)等。

## Prefix/Prompt-Tuning

前缀或提示词微调，是一种常见的参数高效微调方法，它冻结了模型的参数，而仅对输入的前缀或提示词进行调整。

### 离散提示词（Discrete Prompt）

离散提示词是指使用人为设计的提示词模板，针对特定的下游任务设计特定的提示词，基本的分为针对任务的提示词模板和从输出到标签的映射。确定合适的离散提示词，往往需要进行搜索。离散提示词事实上利用了大语言模型的上下文学习能力，但其效果有限。

### 提示词调优（Prompt Tuning）

提示词调优将离散提示词中的提示词从离散的标记可能转换为连续的表示，即不再是对输入文本加上提示词，而是对输入文本得到的嵌入前加上 k 个可学习的嵌入，这些嵌入可以通过梯度下降学习，他们不一定有在词表中对应的标记表示，即使有也可能不符合自然语言的习惯。训练过程，我们仅学习这 k 个嵌入向量，而冻结模型的参数。这 k 个嵌入向量可以随机初始化，也可以从原有模型的词表中抽取词的嵌入初始化。

### P-Tuning

P-Tuning相对于提示词调优做了一些改变，一方面它允许提示嵌入向量加入输入文本嵌入向量的中间任意位置，而不仅仅是简单的拼接，另一方面，它使用了一个提示词编码器，从软提示得到提示嵌入向量，而不是直接学习提示嵌入向量，发明该方法的作者认为，直接学习提示嵌入向量可能导致局部最优。提示词编码器一般是由一个 Bi-LSTM 和一个两层的前馈神经网络组成。使用提示词编码器事实上是一个重参数化的过程。

### P-Tuning-v2

P-Tuning-v2相对于P-Tuning又有了一些改变，它将提示嵌入向量插入到每个Transformer块的输入，而不仅仅是嵌入层的输出，同时，它移除了P-Tuning中的重参数化过程，即不再使用软提示和提示词编码器，而是直接学习嵌入向量。

### 前缀调优（Prefix Tuning）

前缀调优与提示词调优类似，不同之处在于，它给模型每个Transformer层的输入都加上一个前缀，而不是仅给输入嵌入层的输出加上前缀。前缀调优一般应用于生成任务，可以取得更好的效果。

## 适配器调优

不同于前缀或提示词调优，适配器调优直接改变了网络的结构，给Transformer块增加了一些新的网络层，训练时固定原有的模型参数，而仅训练新增的参数，新增的网络层称为适配器，一般加在多头注意力后和前馈网络层后。适配器一般是由一个下投影、一个非线性层和一个上投影组成，类似一个瓶颈状的结构。适配器调优分有串行和并行两类，其基本示意图如下（图片来自[知乎文章](https://zhuanlan.zhihu.com/p/621700272)）

![adapter-tuning](https://pic3.zhimg.com/v2-33866038c400efe8a8b16dcc72be654c_1440w.jpg)

## LoRA

LoRA是当前最常用的参数高效微调方法之一，其英文全称是Low-Rank Adaptation，即低秩适应。其基本思想是，我们训练权重矩阵，限定其变化量为一个低秩矩阵，从而可以用一个下投影和上投影表示，这事实上就是并行的适配器调优（至少我没有看出二者的区别）。原论文中仅在注意力矩阵上加上了LoRA，事实上前馈网络也是可以加上LoRA的。一般的，下投影矩阵记为 $A$ ，上投影矩阵记为 $B$ ， $A$ 通常进行随机初始化，即服从 $N(0,\sigma^2)$ 分布，而 $B$ 通常初始化为 $0$ ，这使得开始的时候变化量事实上为 $0$ 。模型结构示意图如下（图片来自[知乎文章](https://zhuanlan.zhihu.com/p/621700272)）

![LoRA](https://pic3.zhimg.com/v2-9f5da4dc36952fc2342015984508a63e_1440w.jpg)
