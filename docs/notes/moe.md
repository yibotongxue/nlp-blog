---
head:
  - - link
    - rel: stylesheet
      href: https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css
---

# 混合专家模型

本文介绍混合专家模型之发展，系COS597G课程第十六讲之笔记，并结合其后更新的发展。参考[COS597G第十六讲讲义](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec16.pdf)，[论文](https://arxiv.org/pdf/2112.04426.pdf)，[知乎文章](https://zhuanlan.zhihu.com/p/674698482)和[DeepSeek技术报告](https://arxiv.org/pdf/2412.19437)及其[中文翻译的知乎文章](https://zhuanlan.zhihu.com/p/14890557782)。

## 简单介绍

所谓混合专家模型，较为通俗的理解即训练许多的小型的专家模型，并有一个路由网络决定专家的分配（理论上常是概率的分配，而又常只选择概率最高的若干个专家，因而也有专家选择之说）。

### 稀疏性

通常的大语言模型，比如GPT-3，一次推理中其所有的参数都需要参与计算，称为稠密模型；对于使用混合专家架构之模型，一次推理中仅会使用到若干个专家，而不是全部，即仅激活部分的参数，因而被称为稀疏模型。具体来说，一般会有一个路由网络，一个标记输入其中，其会计算得到每一个专家之于这个标记的门控值，选择最佳的若干个专家，将标记输入，在按照门控值对输出加权求和。一个比较简单的门控函数即一个线性层和一个Softmax操作实现。

:::details 关于 token 的翻译
大语言模型中的 token 一词的翻译一直存在争议，普遍的翻译是令牌，一些人主张翻译为词元，也有一些人主张使用英文单词，这里我们将其翻译为标记。

翻译成令牌确实有不妥之处，因为大语言模型中的 token 并不是令牌的意思，翻译作令牌事实上是采用的是 token 的另一个意思，但事实上也不会影响人们的理解；翻译成词元，事实上是词法分析中的概念，一定意义上很准确表达了大语言模型中的 token 的含义，但对于视觉转换器等其他模态的大模型中的 token 则不能很准确的表达；直接使用英文无疑是最不合理的，这相当于回避了翻译的问题；而标记既能表达词法分析中的概念，适用于语言模型中的 token ，又能很好地帮助人们理解其他模态的模型中的 token ，因此这里采用这个翻译。如果查看 Hugging Face相关的文档，会发现其繁体中文版本也是将 token 翻译为标记（標記）或词符（詞符），我认为是比较合适的翻译。
:::

### 转换器中的混合专家模型

混合专家模型的历史可以说到很久以前，最早的论文可以追溯到1991年，在发展历史中，其路由网络、专家网络也各有不同，这里介绍转换其中的混合专家模型。事实上，转换器中的混合专家模型中的专家是前馈网络层，而不是注意力层。具体的，对于编码器和解码器中的自注意力机制之后的前馈网络层替换为混合专家，即一个门控网络（路由网络）和若干个小的前馈网络。可以参考如下的示意图，图片取自[知乎文章](https://zhuanlan.zhihu.com/p/674698482)

![moe-transformer](https://pic1.zhimg.com/v2-f618c8ae586328be1cd3908dd5626736_1440w.jpg)

### 微调

混合专家模型的参数很多，微调的时候很容易造成过拟合，往往需要设置为稀疏层设置较高的 dropout 率。

### 负载均衡

混合专家模型的门控网路可能会偏向将标记路由到几个比较受欢迎的专家，造成这几个专家更新、训练较快，进而导致更可能被选到，最终造成专家负载不均衡。为了解决这个问题，混合专家模型往往需要引入负载均衡机制，比如在门控网络添加噪声，或者限制专家容量，或者设置负载均衡损失等等。

## 切换转换器

下面介绍切换转换器（Switch Transformer）。其基于原先的混合专家模型做了许多的创新。

### 单专家路由

切换转换器对于每一个标记，只将其路由到概率最高的专家，也就是说门控层或者路由层实现的是切换的功能，每次切换到某一个专家。这样做有这些好处：

1. 减少了路由器的计算
2. 专家的批量大小（专家容量）至少可以减少一半
3. 路由实现简单，通信成本降低

### 专家容量

为了均衡每个专家负载的标记，切换转换器设置了专家容量，其为

$$
expert capacity = (\frac{tokens per batch}{number of experts}) \times capacity factor
$$

即平均负载时的容量乘以一个系数——容量因子。当一个批次路由到某个专家的标记超过了专家容量，多余的标记会不经过计算，而直接通过残差连接传递给下一层。增大容量因子可以增加缓冲，以应对专家能力不平衡的情况，但会导致内存和计算的浪费。

在这种设置下，

### 可微负载均衡损失

除了直接通过设置专家容量均衡负载，切换模型还设计了负载均衡损失，以引诱路由网络更均衡的路由标记。对于每一个切换层（门控、路由），专家索引由 $i=1$ 到 $N$ ，每一个批次 $B$ 包含 $T$ 个标记，定义损失

$$
loss = \alpha \cdot N \cdot \sum\limits_{i=1}^Nf_i \cdot P_i
$$

其中 $f_i$ 是分发给专家 $i$ 的标记比例。

$$
f_i = \frac{1}{T} \sum\limits_{x\in B} 1\{argmaxp(x)=i\}
$$

且 $P_i$ 是分配给专家 $i$ 的路由器概率的比例。

$$
P_i = \frac{1}{T} \sum\limits_{x\in B} p_i(x)
$$

每一个损失都会加总到总的损失中。

## DeepSeekMoE

DeepSeek-V3 也采用了混合专家模型，并进行了一些创新。

### 共享专家

DeepSeek-V3 采用更细粒度的专家分配机制，创造性的引入了共享专家，所有的标记都需要经过共享专家，并在其他的普通专家中选择若干个。

### 无辅助损失负载均衡

负载均衡损失事实上与模型的性能没有直接的关系，其引入可能导致模型的性能下降， DeepSeek-V3 使用无辅助损失负载均衡。 DeepSeek-V3 为每个专家引入一个偏置项，将其添加到门控函数得到的概率上，用这个结果确定 top-K 路由，在训练过程中，系统会实时监控每个专家的负载，每个步骤结束的时候，对于那些负载过高的专家，会将其偏置减少 $\gama$ ，其中 $\gama$ 是控制偏置更新速率的超参数。

### 序列级辅助损失补充机制

尽管 DeepSeek-V3 的负载均衡主要通过无辅助损失负载均衡实现，但为了反之单个序列中出现的严重负载不均衡现象，模型还引入了补充的序列级辅助损失，基本与切换转换器中的负载均衡损失一致，其中的 $\alpha$ 值设置为一个极小值。

### 节点约束路由机制

这事实上是一种工程优化策略，不同的专家分布在不同的物理计算节点上，系统限制了每个标记选择的节点数不能超过 $M$ 个，节点的选择基于每个节点上专家的最高 $\frac{K_r}{M}$ 相关度分数总和。在这样的约束下， DeepSeek-V3 能够实现计算与通信的近乎完全并行处理。

### 完整的标记保留机制

得益于 DeepSeek-V3 高效的负载均衡策略，模型训练过程中各个专家保持良好的负载均衡状态，因此训练过程中不会出现标记舍弃的情况。在推理阶段， DeepSeek-V3 同样采用了特定的推理部署策略，实现了推理阶段的完整的标记保留。
