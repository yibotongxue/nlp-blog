---
head:
  - - link
    - rel: stylesheet
      href: https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css
---

# 上下文学习

这部分内容主要参考[知乎文章](https://zhuanlan.zhihu.com/p/606788655)，为学习[COS 579G](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/)中的[第四讲GPT-3](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec04.pdf)的一个补充。

## 上下文学习和GPT-3简介

在[预训练的笔记中](./pretraining)，我们提到了[BERT模型](./pretraining#编码器预训练)、[T5模型](./pretraining#编码器-解码器预训练)和[GPT-2模型](./pretraining#解码器预训练)，这些模型的共同特点是一般先通过大规模数据的学习得到一个通用模型，再在特定的任务数据集上进行微调。当参数量不断增大，到了GPT-3模型是，研究人员发现预训练好的 GPT-3 模型如果要在特定的任务运行，不需要重新训练，只需要提供问题的描述和示例，这个现象被称为上下文学习。

上下文学习能力简单的介绍就是预训练好的通用模型要迁移到特定的任务，不需要重新在特定任务的数据集进行重新训练（即微调），只需要把问题的描述（可选）和若干个示例提供给模型，即可以得到这个问题的查询答案。

上下文学习能力在以往的小的模型中都没有出现，只有在GPT-3这样的参数量很大的模型中才出现，关于其出现原因，可以查看[这篇论文](https://arxiv.org/pdf/2212.10559)，其核心观点为将上下文学习认为一种隐式的微调。以下内容也主要基于这篇论文介绍。

## 注意力机制与通过梯度下降优化的线性层之间的对偶形式

这个读起来很拗口，实际上就是通过梯度下降优化的线性层具有线性注意力的对偶形式，所谓的线性注意力，考虑我们常用的注意力公式

$$
atten = Softmax(\frac{QK^T}{\sqrt{d}})V
$$

其中的 $Softmax$ 操作去掉即为线性注意力。考虑通过提督虾酱有化的线性层

$$
F(x) = (W_0 + \Delta W) x
$$

注意到 $\Delta W$ 可以通过历史累计输入分量 $x_i'$ 和其输出误差信号 $e_i$ 的外积来计算，即

$$
\Delta W = \sum\limits_ie_i\otimes x_i'
$$

我们有

$$
\begin{aligned}
F(x) &= (W_0 + \Delta W) x \\
  &= (W_0 + \sum\limits_ie_i\otimes x_i') x \\
  &= W_0x + \sum\limits_i(e_i\otimes x_i') x \\
  &= W_0x + \sum\limits_ie_i\otimes (x_i^Tx) \\
  &= W_0x + LinearAttn(E,X',x)
\end{aligned}
$$

其中 $LinearAttn(V,K,q)$ 即表示线性注意力机制，我们将误差信号 $E$ 作为值，历史输入 $X'$ 作为键，当前输入 $x$ 作为查询。

## 将 Transformer 注意力机制理解为元优化

这部分的具体推导可以参考论文，这里仅介绍基本的思路，核心的点在于，我们考虑 Transformer 注意力机制的公式，将其中的标准注意力近似为线性注意力，并代入 $Q, K$ 的公式，其中表示可以分为一般的查询输入和示例输入，二者通过矩阵拼接形成总的输入，将一般地查询输入视为初始的参数，而示例输入的线性注意力通过上面提到的对偶形式替换为参数的更新量，即示例输入实际上起到了梯度更新的效果。

## 比较上下文学习与微调

论文还比较了上下文学习和微调，将微调限制为指定示例输入为训练输入，每个示例仅训练一步，使用相同的模板格式化训练示例并使用因果语言建模目标进行微调，然后发现上下文学习与微调具有很多相似之处，总结如下：

1. **都执行梯度下降**
2. **相同的训练信息**
3. **相同的训练示例因果顺序**，示例中的后续令牌不会影响前面的令牌
4. **都针对注意力**，局限于注意力键和值的计算

事实上第二点和第三点都是设计者自己限制微调实现的，但第一点和第四点确实指出了上下文学习与微调确有很多相似之处，将上下文学习类比为隐式的微调是有一定依据的。